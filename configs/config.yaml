# @package _global_

defaults:
  - _self_
  - model: transformer
  - optimizer: adam

# Wandb logging config
wandb:
  project: neural-style-transfer
  entity: null  # Set this to your wandb username
  name: null    # Will be auto-generated if not specified
  tags: []

# Training parameters
training:
  epochs: 4
  batch_size: 8
  image_size: 256  # Will be increased to 512 later
  save_freq: 100   # Save checkpoint every N iterations

# Loss weights
loss:
  content_weight: 1.0
  style_weight: 10.0
  tv_weight: 1e-6

# Optimization flags
optimization:
  amp: true  # Automatic Mixed Precision
  channels_last: true
  cudnn_benchmark: true
  compile: true  # torch.compile (PyTorch 2.0+)

hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
